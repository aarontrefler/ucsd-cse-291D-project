{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we try to predict if two person would result a match and give some importance featurues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "\n",
       "   intel5_3  fun5_3  amb5_3  \n",
       "0       NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "data_df = pd.read_csv(\"../../data/raw/speed_dating_data.csv\", encoding=\"ISO-8859-1\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Nan values in both 'field' and 'field_cd', but there are some entries that 'field' is filled but with 'filed_cd' empty, so we convert them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Numer of ppl did not fill field:\", sum(pd.isnull(data_df['field'])))\n",
    "print(\"Numer of ppl did not fill field_cd:\", sum(pd.isnull(data_df['field_cd'])))\n",
    "print(\"Number of ppl did not fill career:\", sum(pd.isnull(data_df['career'])))\n",
    "\n",
    "# convert all filled field to field code\n",
    "f_fcd = data_df[['field','field_cd']].drop_duplicates() # get all listed filed name and its code\n",
    "nan_ind = pd.isnull(f_fcd).any(1).nonzero()[0] # row has Nan\n",
    "f_fcd.drop(f_fcd.index[nan_ind],inplace=True) # remove rows that has Nan\n",
    "\n",
    "fcd_ind = pd.isnull(data_df['field_cd']).nonzero()[0] # row where 'field_cd' is Nan\n",
    "data_ind = data_df.index\n",
    "n = 0\n",
    "for i in fcd_ind:\n",
    "    field_i = data_df.loc[data_ind[i], 'field']\n",
    "    f_cd = f_fcd[f_fcd['field']==field_i]['field_cd'].values\n",
    "    if pd.isnull(f_cd) == 0: # if the person did not leave 'field' empty\n",
    "        n += 1\n",
    "        data_df.loc[data_ind[i], 'field_cd'] = f_cd[0]\n",
    "print(\"Done converting with {} filed_cd added!\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use some relevant and avaliable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note 'career_c' is incomplete and needs to add\n",
    "# And also 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1' are not filled \n",
    "use_features = ['iid', 'gender', 'wave', 'pid', 'match', 'samerace', 'age_o', 'race_o', \\\n",
    "                 'pf_o_att', 'pf_o_sin', 'pf_o_int','pf_o_fun', 'pf_o_amb', 'pf_o_sha',\\\n",
    "                 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'sports',\\\n",
    "                 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n",
    "                 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n",
    "                 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n",
    "                 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\n",
    "Data_df = data_df[use_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features 1_1, 2_1 are measured differently than 3_1, where former has the rule: \"Waves 6-9: Please rate the importance of the following attributes on a scale of 1-10; Waves 1-5 and 10-21: Please distribute 100 points among the following attributes -- give more points to those attributes that you think are more important to members of the opposite sex when they are deciding whether to date someone. Total points must equal 100.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will change the 100 pts measure to 1~10 scale\n",
    "# First, get all the data where wave 1-5, 10-21 where people use pts measure\n",
    "pts = Data_df[(Data_df['wave']>9)|(Data_df['wave']<6)]\n",
    "pts_ind = pts.index\n",
    "f1 = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "f2 = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "print(Data_df.loc[pts_ind,f1].max())\n",
    "# however, some scale are written in pts\n",
    "scale = Data_df[(Data_df['wave']<10)&(Data_df['wave']>5)]\n",
    "print(\"However, somehow some entries that are supposed to be scale also use pts\\n\", scale[f1].max())\n",
    "# by a closer look, we found that wave 6-9 also uses pts measure on f1 and f2 instead of 1-10 scale\n",
    "scale_pts1 = scale[np.sum(scale[f1]>10,axis=1)==0]\n",
    "scale_pts2 = scale[np.sum(scale[f2]>10,axis=1)==0]\n",
    "print(\"The only one that is not in pts measure are those with Nan value\")\n",
    "scale_pts1[f1+f2]\n",
    "# so we will just keep it as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the vector that contains the information both for the male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first get rid off any rows contain Nan value\n",
    "inds = pd.isnull(Data_df).any(1).nonzero()[0] # row index that contains Nan\n",
    "print(\"number of rows contain Nan:\", len(inds))\n",
    "Data_df= Data_df.drop(Data_df.index[inds])\n",
    "# notice pid is float, so we change it to int\n",
    "Data_df['pid'] = Data_df['pid'].astype(int)\n",
    "Data_df['iid'] = Data_df['iid'].astype(int)\n",
    "\n",
    "mdata_df = Data_df[Data_df['gender']==1]\n",
    "fdata_df = Data_df[Data_df['gender']==0]\n",
    "print(mdata_df.shape)\n",
    "print(fdata_df.shape)\n",
    "same1 = []\n",
    "for i in mdata_df.pid.values:\n",
    "    if i not in fdata_df.iid.values:\n",
    "        same1.append(i)\n",
    "print(\"some guy's partener is not found in fdata:\", list(set(same1)))\n",
    "same2 = []\n",
    "for i in fdata_df.pid.values:\n",
    "    if i not in mdata_df.iid.values:\n",
    "        same2.append(i)\n",
    "print(\"some girl's partener is not found in mdata:\", list(set(same2)))\n",
    "\n",
    "# male features in combination\n",
    "cmfeatures = ['iid', 'pid', 'match', 'samerace', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out',\\\n",
    "             'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n",
    "             'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n",
    "             'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n",
    "             'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\n",
    "new_mdata = mdata_df[cmfeatures]\n",
    "# female features in combination\n",
    "cffeatures = [cmfeatures[0]] + cmfeatures[4:]\n",
    "new_fdata = fdata_df[cffeatures].drop_duplicates()\n",
    "new_data = pd.DataFrame.copy(new_mdata)\n",
    "new_fdata.columns = [i+'_f' for i in cffeatures] # rename the feature name of female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"building data for pairs...\")\n",
    "df = pd.DataFrame()\n",
    "for i in new_mdata.index.values:\n",
    "    m_info = new_mdata.loc[i,:]\n",
    "    pid = new_mdata.loc[i,'pid'] # this is the (female)partener's ID\n",
    "    f_ind = new_fdata.iid_f==pid\n",
    "    if sum(f_ind) !=0: # append only if the pid is found in female iid\n",
    "        f_info_df = new_fdata[f_ind]\n",
    "        f_info = f_info_df.loc[f_info_df.index[0],:]\n",
    "        combined = m_info.append(f_info)\n",
    "        df = df.append(combined,ignore_index=True)\n",
    "# now drop features that we do not need for prediction\n",
    "drop_features = ['iid', 'pid', 'iid_f']\n",
    "print(\"Done making data for pairs\")\n",
    "pair_df = df.drop(drop_features,axis=1)\n",
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us build the model, first, and see the number of each class(0 = no, 1 = yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_train = pair_df.drop('match',axis=1)\n",
    "pair_label = pair_df['match']\n",
    "print(\"total training data size:\", pair_df.shape)\n",
    "pd.Series.value_counts(pair_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a tuned xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 22, 4\n",
    "\n",
    "from time import time\n",
    "\n",
    "# create train and test data\n",
    "train_data, test_data = train_test_split(pair_df, test_size=0.1, random_state=42, stratify=pair_df['match'])\n",
    "predictors = [x for x in pair_df.columns if x not in ['match']]\n",
    "print(\"train shape:\", train_data.shape)\n",
    "print(\"test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(see details :http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtest, predictors,useTrainCV=True, cv_folds=10, early_stopping_rounds=20):\n",
    "    t1 = time()\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['match'].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=['auc'], early_stopping_rounds=early_stopping_rounds, stratified=True)#, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['match'],eval_metric=['auc'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    t2 = time()    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report (took {0:.2f}sec)\".format(t2-t1))\n",
    "    print(\"The result params is:\\n\", alg.get_xgb_params())\n",
    "    print(\"Train Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtrain['match'].values, dtrain_predictions)))\n",
    "    print(\"Train AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtrain['match'], dtrain_predprob)))\n",
    "    print(\"Test Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtest['match'].values, dtest_predictions)))\n",
    "    print(\"Test AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtest['match'], dtest_predprob)))\n",
    "    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    return dtest_predprob, feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = XGBClassifier(learning_rate =0.01,\n",
    "                     n_estimators=5000,\n",
    "                     max_depth=5,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0.4,\n",
    "                     subsample=0.95,\n",
    "                     colsample_bytree=0.65,\n",
    "                     reg_alpha=0.,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=4,\n",
    "                     scale_pos_weight=1,\n",
    "                     seed=27)\n",
    "result = modelfit(clf, train_data, test_data, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 important features: (importance in descending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(result[1].index.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least 10 important features: (importance in ascending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(result[1].index.values[-10:])[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(test_data['match'], result[0])\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see more about auc_roc: https://datamize.wordpress.com/2015/01/24/how-to-plot-a-roc-curve-in-scikit-learn/ and http://gim.unmc.edu/dxtests/roc3.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
