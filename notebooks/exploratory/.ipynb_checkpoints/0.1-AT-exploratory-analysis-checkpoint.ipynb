{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add src/ folder to path\n",
    "import sys\n",
    "src_path = '../../code' \n",
    "sys.path.insert(0, src_path) \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from factor_scatter_matrix import factor_scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "\n",
       "   intel5_3  fun5_3  amb5_3  \n",
       "0       NaN     NaN     NaN  \n",
       "1       NaN     NaN     NaN  \n",
       "2       NaN     NaN     NaN  \n",
       "3       NaN     NaN     NaN  \n",
       "4       NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../../data/raw/speed_dating_data.csv\", encoding=\"ISO-8859-1\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Male Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_m_df = data_df[data_df[\"gender\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use = [\n",
    "    'match',\\\n",
    "    'age', 'go_out', 'sports',\\\n",
    "    'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n",
    "    'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "factor_scatter_matrix(data_m_df[features_to_use], \"match\", figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are Nan values in both 'field' and 'field_cd', but there are some entries that 'field' is filled but with 'filed_cd' empty, so we convert them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of ppl did not fill field: 63\n",
      "Numer of ppl did not fill field_cd: 82\n",
      "Number of ppl did not fill career: 89\n",
      "Done converting with 19 filed_cd added!\n"
     ]
    }
   ],
   "source": [
    "print(\"Numer of ppl did not fill field:\", sum(pd.isnull(data_df['field'])))\n",
    "print(\"Numer of ppl did not fill field_cd:\", sum(pd.isnull(data_df['field_cd'])))\n",
    "print(\"Number of ppl did not fill career:\", sum(pd.isnull(data_df['career'])))\n",
    "\n",
    "# convert all filled field to field code\n",
    "f_fcd = data_df[['field','field_cd']].drop_duplicates() # get all listed filed name and its code\n",
    "nan_ind = pd.isnull(f_fcd).any(1).nonzero()[0] # row has Nan\n",
    "f_fcd.drop(f_fcd.index[nan_ind],inplace=True) # remove rows that has Nan\n",
    "\n",
    "fcd_ind = pd.isnull(data_df['field_cd']).nonzero()[0] # row where 'field_cd' is Nan\n",
    "data_ind = data_df.index\n",
    "n = 0\n",
    "for i in fcd_ind:\n",
    "    field_i = data_df.loc[data_ind[i], 'field']\n",
    "    f_cd = f_fcd[f_fcd['field']==field_i]['field_cd'].values\n",
    "    if pd.isnull(f_cd) == 0: # if the person did not leave 'field' empty\n",
    "        n += 1\n",
    "        data_df.loc[data_ind[i], 'field_cd'] = f_cd[0]\n",
    "print(\"Done converting with {} filed_cd added!\".format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use some relevant and avaliable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# note 'career_c' is incomplete and needs to add\n",
    "# And also 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1' are not filled \n",
    "use_features = ['iid', 'gender', 'wave', 'pid', 'match', 'samerace', 'age_o', 'race_o', \\\n",
    "                 'pf_o_att', 'pf_o_sin', 'pf_o_int','pf_o_fun', 'pf_o_amb', 'pf_o_sha',\\\n",
    "                 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'sports',\\\n",
    "                 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n",
    "                 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n",
    "                 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n",
    "                 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\n",
    "Data_df = data_df[use_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features 1_1, 2_1 are measured differently than 3_1, where former has the rule: \"Waves 6-9: Please rate the importance of the following attributes on a scale of 1-10; Waves 1-5 and 10-21: Please distribute 100 points among the following attributes -- give more points to those attributes that you think are more important to members of the opposite sex when they are deciding whether to date someone. Total points must equal 100.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr1_1     100.0\n",
      "sinc1_1      60.0\n",
      "intel1_1     50.0\n",
      "fun1_1       50.0\n",
      "amb1_1       53.0\n",
      "shar1_1      30.0\n",
      "dtype: float64\n",
      "However, somehow some entries that are supposed to be scale also use pts\n",
      " attr1_1     27.78\n",
      "sinc1_1     23.81\n",
      "intel1_1    23.81\n",
      "fun1_1      27.78\n",
      "amb1_1      20.59\n",
      "shar1_1     23.81\n",
      "dtype: float64\n",
      "The only one that is not in pts measure are those with Nan value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr2_1</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  attr2_1  sinc2_1  \\\n",
       "1866      NaN      NaN       NaN     NaN     NaN      NaN      NaN      NaN   \n",
       "1867      NaN      NaN       NaN     NaN     NaN      NaN      NaN      NaN   \n",
       "1868      NaN      NaN       NaN     NaN     NaN      NaN      NaN      NaN   \n",
       "1869      NaN      NaN       NaN     NaN     NaN      NaN      NaN      NaN   \n",
       "1870      NaN      NaN       NaN     NaN     NaN      NaN      NaN      NaN   \n",
       "\n",
       "      intel2_1  fun2_1  amb2_1  shar2_1  \n",
       "1866       NaN     NaN     NaN      NaN  \n",
       "1867       NaN     NaN     NaN      NaN  \n",
       "1868       NaN     NaN     NaN      NaN  \n",
       "1869       NaN     NaN     NaN      NaN  \n",
       "1870       NaN     NaN     NaN      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will change the 100 pts measure to 1~10 scale\n",
    "# First, get all the data where wave 1-5, 10-21 where people use pts measure\n",
    "pts = Data_df[(Data_df['wave']>9)|(Data_df['wave']<6)]\n",
    "pts_ind = pts.index\n",
    "f1 = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "f2 = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "print(Data_df.loc[pts_ind,f1].max())\n",
    "# however, some scale are written in pts\n",
    "scale = Data_df[(Data_df['wave']<10)&(Data_df['wave']>5)]\n",
    "print(\"However, somehow some entries that are supposed to be scale also use pts\\n\", scale[f1].max())\n",
    "# by a closer look, we found that wave 6-9 also uses pts measure on f1 and f2 instead of 1-10 scale\n",
    "scale_pts1 = scale[np.sum(scale[f1]>10,axis=1)==0]\n",
    "scale_pts2 = scale[np.sum(scale[f2]>10,axis=1)==0]\n",
    "print(\"The only one that is not in pts measure are those with Nan value\")\n",
    "scale_pts1[f1+f2]\n",
    "# so we will just keep it as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the vector that contains the information both for the male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows contain Nan: 336\n",
      "(4007, 57)\n",
      "(4035, 57)\n",
      "some guy's partener is not found in fdata: [416]\n",
      "some girl's partener is not found in mdata: [413, 414]\n"
     ]
    }
   ],
   "source": [
    "# first get rid off any rows contain Nan value\n",
    "inds = pd.isnull(Data_df).any(1).nonzero()[0] # row index that contains Nan\n",
    "print(\"number of rows contain Nan:\", len(inds))\n",
    "Data_df= Data_df.drop(Data_df.index[inds])\n",
    "# notice pid is float, so we change it to int\n",
    "Data_df['pid'] = Data_df['pid'].astype(int)\n",
    "Data_df['iid'] = Data_df['iid'].astype(int)\n",
    "\n",
    "mdata_df = Data_df[Data_df['gender']==1]\n",
    "fdata_df = Data_df[Data_df['gender']==0]\n",
    "print(mdata_df.shape)\n",
    "print(fdata_df.shape)\n",
    "same1 = []\n",
    "for i in mdata_df.pid.values:\n",
    "    if i not in fdata_df.iid.values:\n",
    "        same1.append(i)\n",
    "print(\"some guy's partener is not found in fdata:\", list(set(same1)))\n",
    "same2 = []\n",
    "for i in fdata_df.pid.values:\n",
    "    if i not in mdata_df.iid.values:\n",
    "        same2.append(i)\n",
    "print(\"some girl's partener is not found in mdata:\", list(set(same2)))\n",
    "\n",
    "# male features in combination\n",
    "cmfeatures = ['iid', 'pid', 'match', 'samerace', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out',\\\n",
    "             'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing',\\\n",
    "             'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy',\\\n",
    "             'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr2_1', 'sinc2_1',\\\n",
    "             'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1','fun3_1', 'intel3_1', 'amb3_1']\n",
    "new_mdata = mdata_df[cmfeatures]\n",
    "# female features in combination\n",
    "cffeatures = [cmfeatures[0]] + cmfeatures[4:]\n",
    "new_fdata = fdata_df[cffeatures].drop_duplicates()\n",
    "new_data = pd.DataFrame.copy(new_mdata)\n",
    "new_fdata.columns = [i+'_f' for i in cffeatures] # rename the feature name of female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building data for pairs...\n",
      "Done making data for pairs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_f</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>amb1_1_f</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>amb2_1_f</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>amb3_1_f</th>\n",
       "      <th>art</th>\n",
       "      <th>art_f</th>\n",
       "      <th>...</th>\n",
       "      <th>sports</th>\n",
       "      <th>sports_f</th>\n",
       "      <th>theater</th>\n",
       "      <th>theater_f</th>\n",
       "      <th>tv</th>\n",
       "      <th>tv_f</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>tvsports_f</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yoga_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  age_f  amb1_1  amb1_1_f  amb2_1  amb2_1_f  amb3_1  amb3_1_f  art  \\\n",
       "0  27.0   21.0     0.0      15.0    25.0       5.0     5.0       7.0  5.0   \n",
       "1  27.0   24.0     0.0       0.0    25.0       0.0     5.0       3.0  5.0   \n",
       "2  27.0   25.0     0.0      10.0    25.0       0.0     5.0       8.0  5.0   \n",
       "3  27.0   23.0     0.0      10.0    25.0       5.0     5.0       8.0  5.0   \n",
       "4  27.0   21.0     0.0      10.0    25.0       5.0     5.0       8.0  5.0   \n",
       "\n",
       "   art_f   ...    sports  sports_f  theater  theater_f   tv  tv_f  tvsports  \\\n",
       "0    1.0   ...       8.0       9.0      4.0        1.0  2.0   9.0       7.0   \n",
       "1    6.0   ...       8.0       3.0      4.0        9.0  2.0   1.0       7.0   \n",
       "2    5.0   ...       8.0       3.0      4.0        7.0  2.0   8.0       7.0   \n",
       "3    7.0   ...       8.0       1.0      4.0        9.0  2.0   7.0       7.0   \n",
       "4    8.0   ...       8.0       7.0      4.0        6.0  2.0   8.0       7.0   \n",
       "\n",
       "   tvsports_f  yoga  yoga_f  \n",
       "0         2.0   1.0     1.0  \n",
       "1         2.0   1.0     1.0  \n",
       "2         8.0   1.0     7.0  \n",
       "3         1.0   1.0     8.0  \n",
       "4         4.0   1.0     3.0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"building data for pairs...\")\n",
    "df = pd.DataFrame()\n",
    "for i in new_mdata.index.values:\n",
    "    m_info = new_mdata.loc[i,:]\n",
    "    pid = new_mdata.loc[i,'pid'] # this is the (female)partener's ID\n",
    "    f_ind = new_fdata.iid_f==pid\n",
    "    if sum(f_ind) !=0: # append only if the pid is found in female iid\n",
    "        f_info_df = new_fdata[f_ind]\n",
    "        f_info = f_info_df.loc[f_info_df.index[0],:]\n",
    "        combined = m_info.append(f_info)\n",
    "        df = df.append(combined,ignore_index=True)\n",
    "# now drop features that we do not need for prediction\n",
    "drop_features = ['iid', 'pid', 'iid_f']\n",
    "print(\"Done making data for pairs\")\n",
    "pair_df = df.drop(drop_features,axis=1)\n",
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'age_f', 'amb1_1', 'amb1_1_f', 'amb2_1', 'amb2_1_f', 'amb3_1',\n",
       "       'amb3_1_f', 'art', 'art_f', 'attr1_1', 'attr1_1_f', 'attr2_1',\n",
       "       'attr2_1_f', 'attr3_1', 'attr3_1_f', 'clubbing', 'clubbing_f',\n",
       "       'concerts', 'concerts_f', 'date', 'date_f', 'dining', 'dining_f',\n",
       "       'exercise', 'exercise_f', 'exphappy', 'exphappy_f', 'field_cd',\n",
       "       'field_cd_f', 'fun1_1', 'fun1_1_f', 'fun2_1', 'fun2_1_f', 'fun3_1',\n",
       "       'fun3_1_f', 'gaming', 'gaming_f', 'go_out', 'go_out_f', 'goal',\n",
       "       'goal_f', 'hiking', 'hiking_f', 'imprace', 'imprace_f', 'imprelig',\n",
       "       'imprelig_f', 'intel1_1', 'intel1_1_f', 'intel2_1', 'intel2_1_f',\n",
       "       'intel3_1', 'intel3_1_f', 'match', 'movies', 'movies_f', 'museums',\n",
       "       'museums_f', 'music', 'music_f', 'race', 'race_f', 'reading',\n",
       "       'reading_f', 'samerace', 'shar1_1', 'shar1_1_f', 'shar2_1', 'shar2_1_f',\n",
       "       'shopping', 'shopping_f', 'sinc1_1', 'sinc1_1_f', 'sinc2_1',\n",
       "       'sinc2_1_f', 'sinc3_1', 'sinc3_1_f', 'sports', 'sports_f', 'theater',\n",
       "       'theater_f', 'tv', 'tv_f', 'tvsports', 'tvsports_f', 'yoga', 'yoga_f'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us build the model, first, and see the number of each class(0 = no, 1 = yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training data size: (3999, 88)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    3345\n",
       "1.0     654\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_train = pair_df.drop('match',axis=1)\n",
    "pair_label = pair_df['match']\n",
    "print(\"total training data size:\", pair_df.shape)\n",
    "pd.Series.value_counts(pair_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use a tuned xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (3599, 88)\n",
      "test shape: (400, 88)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 22, 4\n",
    "\n",
    "from time import time\n",
    "\n",
    "# create train and test data\n",
    "train_data, test_data = train_test_split(pair_df, test_size=0.1, random_state=42, stratify=pair_df['match'])\n",
    "predictors = [x for x in pair_df.columns if x not in ['match']]\n",
    "print(\"train shape:\", train_data.shape)\n",
    "print(\"test shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(see details :http://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtest, predictors,useTrainCV=True, cv_folds=10, early_stopping_rounds=20):\n",
    "    t1 = time()\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain['match'].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics=['auc'], early_stopping_rounds=early_stopping_rounds, stratified=True)#, show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['match'],eval_metric=['auc'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    #Predict test set:\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    t2 = time()    \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report (took {0:.2f}sec)\".format(t2-t1))\n",
    "    print(\"The result params is:\\n\", alg.get_xgb_params())\n",
    "    print(\"Train Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtrain['match'].values, dtrain_predictions)))\n",
    "    print(\"Train AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtrain['match'], dtrain_predprob)))\n",
    "    print(\"Test Accuracy: {0:.2f}%\".format(metrics.accuracy_score(dtest['match'].values, dtest_predictions)))\n",
    "    print(\"Test AUC Score: {0:.4f}\".format(metrics.roc_auc_score(dtest['match'], dtest_predprob)))\n",
    "    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    return dtest_predprob, feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e0ec32dc89a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                      \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                      seed=27)\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-29f4fa46d124>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, dtrain, dtest, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mxgtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'match'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n\u001b[0;32m----> 7\u001b[0;31m             metrics=['auc'], early_stopping_rounds=early_stopping_rounds, stratified=True)#, show_progress=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    398\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarontrefler_temp2/anaconda/envs/py35/lib/python3.5/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate =0.01,\n",
    "                     n_estimators=5000,\n",
    "                     max_depth=5,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0.4,\n",
    "                     subsample=0.95,\n",
    "                     colsample_bytree=0.65,\n",
    "                     reg_alpha=0.,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=4,\n",
    "                     scale_pos_weight=1,\n",
    "                     seed=27)\n",
    "result = modelfit(clf, train_data, test_data, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 important features: (importance in descending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(result[1].index.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least 10 important features: (importance in ascending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(result[1].index.values[-10:])[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(test_data['match'], result[0])\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see more about auc_roc: https://datamize.wordpress.com/2015/01/24/how-to-plot-a-roc-curve-in-scikit-learn/ and http://gim.unmc.edu/dxtests/roc3.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
